{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym  # Use gymnasium instead of gym\n",
    "from gymnasium.spaces import Discrete, Box  # Use gymnasium spaces\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import SAC\n",
    "from gymnasium import spaces\n",
    "import re\n",
    "import csv\n",
    "# Entorno personalizado para el trading de acciones\n",
    "class StockTradingEnv(gym.Env):\n",
    "    def __init__(self, df, initial_balance=10000, shares_per_step=10, commission=0.001, render_mode=None):\n",
    "        super().__init__()\n",
    "        self.df = df  # DataFrame con los datos del mercado\n",
    "        self.initial_balance = initial_balance  # Balance inicial\n",
    "        self.balance = initial_balance  # Balance actual\n",
    "        self.net_worth = initial_balance  # Patrimonio neto actual\n",
    "        self.shares_held = 0  # Cantidad de acciones en posesión\n",
    "        self.shares_per_step = shares_per_step  # Cantidad de acciones a comprar/vender en cada paso\n",
    "        self.commission = commission  # Comisión por transacción\n",
    "        self.current_step = 0  # Paso actual en el entorno\n",
    "        self.reward_range = (-float('inf'), float('inf'))  # Rango de recompensas\n",
    "        self.action_space = Discrete(3)  # Espacio de acciones: 0: hold, 1: buy, 2: sell\n",
    "        self.observation_space = Box(low=0, high=1, shape=(5,), dtype=np.float32)  # Espacio de observaciones\n",
    "        self.render_mode = render_mode  # Modo de renderización\n",
    "        self.action_history = []  # Historial de acciones\n",
    "        self.observation_space = Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
    "\n",
    "    # Función para generar la siguiente observación\n",
    "    def _next_observation(self):\n",
    "        frame = np.array([\n",
    "            self.df.iloc[self.current_step]['Close'] / 1000,  # Precio de cierre escalado\n",
    "            self.df.iloc[self.current_step]['Volume'] / 1000000,  # Volumen escalado\n",
    "            self.balance / self.initial_balance,  # Balance relativo al balance inicial\n",
    "            self.shares_held / 100,  # Acciones en posesión escaladas\n",
    "            self.net_worth / self.initial_balance,  # Patrimonio neto relativo al balance inicial\n",
    "        ], dtype=np.float32)\n",
    "        return frame\n",
    "\n",
    "    # Función para realizar una acción\n",
    "    def _take_action(self, action):\n",
    "        current_price = self.df.iloc[self.current_step]['Close']  # Precio actual\n",
    "        trade_quantity = self.shares_per_step  # Cantidad a transar\n",
    "        cost = trade_quantity * current_price * (1 + self.commission)  # Costo de la transacción\n",
    "\n",
    "        if action == 1:  # Comprar\n",
    "            if self.balance >= cost:  # Verificar si hay suficiente balance\n",
    "                self.balance -= cost  # Reducir el balance\n",
    "                self.shares_held += trade_quantity  # Aumentar las acciones en posesión\n",
    "        elif action == 2:  # Vender\n",
    "            if self.shares_held >= trade_quantity:  # Verificar si hay suficientes acciones\n",
    "                self.balance += trade_quantity * current_price * (1 - self.commission)  # Aumentar el balance\n",
    "                self.shares_held -= trade_quantity  # Reducir las acciones en posesión\n",
    "\n",
    "        self.net_worth = self.balance + self.shares_held * current_price  # Calcular el patrimonio neto\n",
    "\n",
    "    # Función para realizar un paso en el entorno\n",
    "    def step(self, action):\n",
    "        terminated = self.current_step >= len(self.df) - 1  # Verificar si el episodio ha terminado\n",
    "        truncated = False  # No se utiliza en este entorno\n",
    "\n",
    "        if not terminated:\n",
    "            self.current_step += 1  # Avanzar al siguiente paso\n",
    "            self._take_action(action)  # Realizar la acción\n",
    "            obs = self._next_observation()  # Obtener la siguiente observación\n",
    "            reward = (self.net_worth - self.initial_balance) / self.initial_balance  # Calcular la recompensa\n",
    "        else:\n",
    "            obs = self._next_observation()  # Obtener la observación final\n",
    "            reward = 0  # Recompensa cero al final del episodio\n",
    "\n",
    "        info = {'step': self.current_step, 'balance': self.balance, 'shares_held': self.shares_held, 'net_worth': self.net_worth}  # Información adicional\n",
    "        self.action_history.append([self.current_step, action, self.df.iloc[self.current_step]['Close']])  # Registrar la acción\n",
    "        return obs, reward, terminated, truncated, info  # Devolver los resultados\n",
    "\n",
    "    # Función para renderizar el entorno (opcional)\n",
    "    def render(self, mode='human'):\n",
    "        if self.render_mode is not None:\n",
    "            print(f'Step: {self.current_step}')\n",
    "            print(f'Balance: {self.balance}')\n",
    "            print(f'Shares held: {self.shares_held}')\n",
    "            print(f'Net worth: {self.net_worth}')\n",
    "\n",
    "    # Función para resetear el entorno\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.balance = self.initial_balance  # Resetear el balance\n",
    "        self.net_worth = self.initial_balance  # Resetear el patrimonio neto\n",
    "        self.shares_held = 0  # Resetear las acciones en posesión\n",
    "        self.current_step = 0  # Resetear el paso actual\n",
    "        obs = self._next_observation()  # Obtener la observación inicial\n",
    "        info = {}  # Información adicional\n",
    "        self.action_history = []  # Resetear el historial de acciones\n",
    "        return obs, info  # Devolver la observación y la información\n",
    "\n",
    "# Entorno personalizado para el trading de acciones compatible con SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym  # Use gymnasium instead of gym\n",
    "from gymnasium.spaces import Discrete, Box  # Use gymnasium spaces\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import SAC\n",
    "from gymnasium import spaces\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Entorno personalizado para el trading de acciones compatible con SAC\n",
    "class StockTradingEnvSAC(gym.Env):\n",
    "    def __init__(self, df, initial_balance=10000, shares_per_step=10, commission=0.001, render_mode=None):\n",
    "        super().__init__()\n",
    "        self.df = df  # DataFrame con los datos del mercado\n",
    "        self.initial_balance = initial_balance  # Balance inicial\n",
    "        self.balance = initial_balance  # Balance actual\n",
    "        self.net_worth = initial_balance  # Patrimonio neto actual\n",
    "        self.shares_held = 0  # Cantidad de acciones en posesión\n",
    "        self.shares_per_step = shares_per_step  # Cantidad de acciones a comprar/vender en cada paso\n",
    "        self.commission = commission  # Comisión por transacción\n",
    "        self.current_step = 0  # Paso actual en el entorno\n",
    "        self.reward_range = (-float('inf'), float('inf'))  # Rango de recompensas\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)  # Espacio de acciones continuo\n",
    "        self.observation_space = Box(low=0, high=1, shape=(5,), dtype=np.float32)  # Espacio de observaciones\n",
    "        self.render_mode = render_mode  # Modo de renderización\n",
    "        self.action_history = []  # Historial de acciones\n",
    "        self.observation_space = Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
    "\n",
    "    # Función para generar la siguiente observación\n",
    "    def _next_observation(self):\n",
    "        frame = np.array([\n",
    "            self.df.iloc[self.current_step]['Close'] / 1000,  # Precio de cierre escalado\n",
    "            self.df.iloc[self.current_step]['Volume'] / 1000000,  # Volumen escalado\n",
    "            self.balance / self.initial_balance,  # Balance relativo al balance inicial\n",
    "            self.shares_held / 100,  # Acciones en posesión escaladas\n",
    "            self.net_worth / self.initial_balance,  # Patrimonio neto relativo al balance inicial\n",
    "        ], dtype=np.float32)\n",
    "        return frame\n",
    "\n",
    "    # Función para realizar una acción\n",
    "    def _take_action(self, action):\n",
    "        current_price = self.df.iloc[self.current_step]['Close']  # Precio actual\n",
    "        trade_quantity = self.shares_per_step * action[0]  # Cantidad a transar, ajustada por la acción\n",
    "\n",
    "        cost = abs(trade_quantity) * current_price * (1 + self.commission)  # Costo de la transacción\n",
    "\n",
    "        if action[0] > 0:  # Comprar\n",
    "            if self.balance >= cost:  # Verificar si hay suficiente balance\n",
    "                self.balance -= cost  # Reducir el balance\n",
    "                self.shares_held += trade_quantity  # Aumentar las acciones en posesión\n",
    "        elif action[0] < 0:  # Vender\n",
    "            if self.shares_held >= abs(trade_quantity):  # Verificar si hay suficientes acciones\n",
    "                self.balance += abs(trade_quantity) * current_price * (1 - self.commission)  # Aumentar el balance\n",
    "                self.shares_held -= abs(trade_quantity)  # Reducir las acciones en posesión\n",
    "\n",
    "        self.net_worth = self.balance + self.shares_held * current_price  # Calcular el patrimonio neto\n",
    "\n",
    "    # Función para realizar un paso en el entorno\n",
    "    def step(self, action):\n",
    "        terminated = self.current_step >= len(self.df) - 1  # Verificar si el episodio ha terminado\n",
    "        truncated = False  # No se utiliza en este entorno\n",
    "\n",
    "        if not terminated:\n",
    "            self.current_step += 1  # Avanzar al siguiente paso\n",
    "            self._take_action(action)  # Realizar la acción\n",
    "            obs = self._next_observation()  # Obtener la siguiente observación\n",
    "            reward = (self.net_worth - self.initial_balance) / self.initial_balance  # Calcular la recompensa\n",
    "        else:\n",
    "            obs = self._next_observation()  # Obtener la observación final\n",
    "            reward = 0  # Recompensa cero al final del episodio\n",
    "\n",
    "        info = {'step': self.current_step, 'balance': self.balance, 'shares_held': self.shares_held, 'net_worth': self.net_worth}  # Información adicional\n",
    "        self.action_history.append([self.current_step, action, self.df.iloc[self.current_step]['Close']])  # Registrar la acción\n",
    "        return obs, reward, terminated, truncated, info  # Devolver los resultados\n",
    "\n",
    "    # Función para renderizar el entorno (opcional)\n",
    "    def render(self, mode='human'):\n",
    "        if self.render_mode is not None:\n",
    "            print(f'Step: {self.current_step}')\n",
    "            print(f'Balance: {self.balance}')\n",
    "            print(f'Shares held: {self.shares_held}')\n",
    "            print(f'Net worth: {self.net_worth}')\n",
    "\n",
    "    # Función para resetear el entorno\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.balance = self.initial_balance  # Resetear el balance\n",
    "        self.net_worth = self.initial_balance  # Resetear el patrimonio neto\n",
    "        self.shares_held = 0  # Resetear las acciones en posesión\n",
    "        self.current_step = 0  # Resetear el paso actual\n",
    "        obs = self._next_observation()  # Obtener la observación inicial\n",
    "        info = {}  # Información adicional\n",
    "        self.action_history = []  # Resetear el historial de acciones\n",
    "        return obs, info  # Devolver la observación y la información\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ppo_model(train_data_path, base_path):\n",
    "    \"\"\"\n",
    "    Entrena un modelo PPO con los datos de entrenamiento proporcionados.\n",
    "\n",
    "    Args:\n",
    "        train_data_path (str): Ruta al archivo CSV de datos de entrenamiento.\n",
    "        base_path (str): Ruta base del proyecto para guardar el CSV de resultados.\n",
    "    \"\"\"\n",
    "    # Cargar los datos de entrenamiento\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "\n",
    "    # Crear y verificar el entorno de entrenamiento\n",
    "    train_env = StockTradingEnv(train_df, render_mode=None)\n",
    "    check_env(train_env)\n",
    "\n",
    "    # Vectorizar el entorno de entrenamiento\n",
    "    vec_env = DummyVecEnv([lambda: train_env])\n",
    "\n",
    "  \n",
    "    # Definir rangos de hiperparámetros\n",
    "    learning_rates = [0.00007]  # Tasas de aprendizaje\n",
    "    gammas = [0.99]  # Factores de descuento\n",
    "    n_steps_list = [128]  # Número de pasos antes de actualizar el modelo\n",
    "    ent_coefs = [0.01]  # Coeficientes de la pérdida de entropía\n",
    "    vf_coefs = [0.5]  # Coeficientes de la pérdida de la función de valor\n",
    "    max_grad_norms = [0.5]  # Valores máximos para la normalización del gradiente\n",
    "    gae_lambdas = [0.95]  # GAE lambda parameter\n",
    "    batch_sizes = [128]  # Batch size\n",
    "\n",
    "    \n",
    "    # # Definir rangos de hiperparámetros para PPO\n",
    "    # learning_rates = [0.0001, 0.0003, 0.0007, 0.001]  # Tasas de aprendizaje\n",
    "    # gammas = [0.95, 0.97, 0.99]  # Factores de descuento\n",
    "    # n_steps_list = [64, 128, 256]  # Número de pasos antes de actualizar el modelo\n",
    "    # ent_coefs = [0.01, 0.02, 0.05]  # Coeficientes de la pérdida de entropía\n",
    "    # vf_coefs = [0.5, 0.7, 0.9]  # Coeficientes de la pérdida de la función de valor\n",
    "    # max_grad_norms = [0.5, 1.0, 1.5]  # Valores máximos para la normalización del gradiente\n",
    "    # gae_lambdas = [0.9, 0.95, 0.99]  # GAE lambda parameter\n",
    "    # batch_sizes = [64, 128, 256]  # Batch size\n",
    "\n",
    "    # Extract information from the training data path\n",
    "    train_data_filename = os.path.basename(train_data_path)\n",
    "    is_filtered = \"no_filtrado\" not in train_data_path\n",
    "    is_normalized = \"no_normalizado\" not in train_data_path\n",
    "\n",
    "    # CSV file path\n",
    "    csv_file = os.path.join(base_path, \"training_results.csv\")\n",
    "    file_exists = os.path.isfile(csv_file)\n",
    "\n",
    "    # Iterar a través de las combinaciones de hiperparámetros\n",
    "    for learning_rate in learning_rates:\n",
    "        for gamma in gammas:\n",
    "            for n_steps in n_steps_list:\n",
    "                for ent_coef in ent_coefs:\n",
    "                    for vf_coef in vf_coefs:\n",
    "                        for max_grad_norm in max_grad_norms:\n",
    "                            for gae_lambda in gae_lambdas:\n",
    "                                for batch_size in batch_sizes:\n",
    "                                    # Definir el nombre del modelo\n",
    "                                    model_name = f\"ppo_lr{learning_rate}_gamma{gamma}_nsteps{n_steps}_ent{ent_coef}_vf{vf_coef}_gradnorm{max_grad_norm}_gae{gae_lambda}_batch{batch_size}\"\n",
    "\n",
    "                                    # Crear la carpeta para los entrenamientos\n",
    "                                    training_folder = os.path.join(os.path.dirname(train_data_path), \"entrenamientos\", \"PPO\")\n",
    "                                    os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "                                    # Crear la carpeta para el modelo entrenado\n",
    "                                    model_folder = os.path.join(training_folder, model_name)\n",
    "                                    os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "                                    model_path = os.path.join(model_folder, \"model\")\n",
    "\n",
    "                                    print(f\"Entrenando modelo: {model_name}\")\n",
    "\n",
    "                                    # Entrenar el modelo\n",
    "                                    model = PPO('MlpPolicy', vec_env, learning_rate=learning_rate, gamma=gamma, n_steps=n_steps,\n",
    "                                                ent_coef=ent_coef, vf_coef=vf_coef, max_grad_norm=max_grad_norm, gae_lambda=gae_lambda,\n",
    "                                                batch_size=batch_size, verbose=0, device='cpu')\n",
    "                                    # # Entrenar el modelo\n",
    "                                    # model = PPO('MlpPolicy',vec_env,verbose=0, device='cpu')\n",
    "                                    model.learn(total_timesteps=10000)\n",
    "\n",
    "                                    # Guardar el modelo\n",
    "                                    model.save(model_path)\n",
    "                                    print(f\"Modelo guardado en: {model_path}\")\n",
    "\n",
    "                                    # Guardar las estadísticas de entrenamiento\n",
    "                                    stats_path = os.path.join(model_folder, \"stats.txt\")\n",
    "                                    with open(stats_path, \"w\") as f:\n",
    "                                        f.write(f\"Tasa de Aprendizaje: {learning_rate}\\n\")\n",
    "                                        f.write(f\"Gamma: {gamma}\\n\")\n",
    "                                        f.write(f\"N Pasos: {n_steps}\\n\")\n",
    "                                        f.write(f\"Ent Coef: {ent_coef}\\n\")\n",
    "                                        f.write(f\"VF Coef: {vf_coef}\\n\")\n",
    "                                        f.write(f\"Max Grad Norm: {max_grad_norm}\\n\")\n",
    "                                        f.write(f\"GAE Lambda: {gae_lambda}\\n\")\n",
    "                                        f.write(f\"Batch Size: {batch_size}\\n\")\n",
    "                                    print(f\"Estadísticas de entrenamiento guardadas en: {stats_path}\")\n",
    "\n",
    "                                    # Extract algorithm name from the model path\n",
    "                                    algorithm_name = os.path.basename(os.path.dirname(os.path.dirname(model_path)))\n",
    "\n",
    "                                    # Use a more robust regex to extract parameters\n",
    "                                    params = re.findall(r\"([a-z]+)([0-9\\.e-]+)\", model_name)\n",
    "                                    params_dict = {p[0]: p[1] for p in params}\n",
    "\n",
    "                                    # Write to CSV\n",
    "                                    with open(csv_file, mode='a', newline='') as f:\n",
    "                                        writer = csv.writer(f)\n",
    "                                        if not file_exists:\n",
    "                                            writer.writerow([\n",
    "                                                \"Algorithm\", \"Learning Rate\", \"Gamma\", \"N Steps\", \"Ent Coef\", \"VF Coef\", \"Max Grad Norm\", \"GAE Lambda\", \"Batch Size\",\n",
    "                                                \"Train Data\", \"Filtered\", \"Normalized\"\n",
    "                                            ])\n",
    "                                            file_exists = True  # Ensure header is only written once\n",
    "\n",
    "                                        writer.writerow([\n",
    "                                            algorithm_name, params_dict.get(\"lr\", \"\"), params_dict.get(\"gamma\", \"\"), params_dict.get(\"nsteps\", \"\"),\n",
    "                                            params_dict.get(\"ent\", \"\"), params_dict.get(\"vf\", \"\"), params_dict.get(\"gradnorm\", \"\"), params_dict.get(\"gae\", \"\"), params_dict.get(\"batch\", \"\"),\n",
    "                                            train_data_filename, is_filtered, is_normalized\n",
    "                                        ])\n",
    "\n",
    "    print(f\"Estadísticas de entrenamiento guardadas en: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'fxdata15norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m train_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfxdata15norm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./resultados_entrenamiento_15_min\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtrain_ppo_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m, in \u001b[0;36mtrain_ppo_model\u001b[1;34m(train_data_path, base_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mEntrena un modelo PPO con los datos de entrenamiento proporcionados.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    base_path (str): Ruta base del proyecto para guardar el CSV de resultados.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Cargar los datos de entrenamiento\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Crear y verificar el entorno de entrenamiento\u001b[39;00m\n\u001b[0;32m     13\u001b[0m train_env \u001b[38;5;241m=\u001b[39m StockTradingEnv(train_df, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cyber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cyber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\cyber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cyber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\cyber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'fxdata15norm'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym  # Use gymnasium instead of gym\n",
    "from gymnasium.spaces import Discrete, Box  # Use gymnasium spaces\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import SAC\n",
    "from gymnasium import spaces\n",
    "import re\n",
    "import csv\n",
    "train_data_path = \"fxdata15norm\"\n",
    "\n",
    "\n",
    "base_path = \"./resultados_entrenamiento_15_min\"\n",
    "train_ppo_model(train_data_path, base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
